# SPDX-FileCopyrightText: Copyright DB InfraGO AG and contributors
# SPDX-License-Identifier: Apache-2.0

#########################################
### APPLICATION RELATED CONFIGURATION ###
#########################################

# Replicas for all deployments (defaults to 1)
replicaCount:
  backend: 2
  backendPostgres: 1
  valkey: 1
  docs: 1
  frontend: 2
  grafana: 1
  grafanaNginx: 1
  guacamole: 1
  guacamolePostgres: 1
  guacd: 1
  prometheus: 1
  prometheusNginx: 1
  routing: 2

docker:
  registry:
    # DockerHub Registry
    external: &externalRegistry docker.io

    # GitHub Container Registry
    github: ghcr.io

    # Capella Collaboration Manager Docker Registry
    internal: ghcr.io/dsd-dbs/capella-collab-manager

    # Default registry for session containers
    # Only used for the initial deployment
    # Can be customized in the UI after initial deployment
    sessions: ghcr.io/dsd-dbs/capella-dockerimages

  # Docker tag for the internal images (e.g. main)
  tag: main

  # Optional section to overwrite images.
  # The images have to be in the format <registry>/<image>:<tag>
  # If not set, the images are derived from registry, image name and tag.
  images:
    guacamole:
      # To avoid Guacamole restarts on every deployment, the Guacamole image can be set to a specific version.
      guacamole: null
      guacd: null

    frontend: null
    backend: null
    docs: null

    promtail: null
    postgres: null
    valkey: null
    grafana: null
    nginxUnprivileged: null
    mockOauth2Server: null
    prometheus: null
    smtp4dev: null

general:
  # Base URL on which the service listens
  host: localhost

  # In the local development setup, use the following values:
  # - HTTP: 8080
  # - HTTPS: 443
  port: 443

  # In the local development setup, use the following values:
  # - HTTP: http
  # - HTTPS: https
  scheme: https

  # The application will serve on all hostnames (wildcardHost set to True).
  # The default behavior is to only serve on the configured host (wildcardHost set to False).
  # This option has no effect when using OpenShift.
  wildcardHost: False

sessions:
  # Session timeout in minutes for unused and idle sessions
  timeout: 90

pipelines:
  # Pipeline timeout in minutes
  timeout: 60

database:
  # Database Configuration for Guacamole
  guacamole:
    # Define whether the database should also be deployed
    # in the cluster or whether it already exists externally.
    deploy: True

    internal:
      ###### IF database.guacamole.deploy == True ######

      # Admin password of the database
      password: null

    external:
      ###### IF database.guacamole.deploy == False ######

      # Select type of external database
      # Possible values: MYSQL | POSTGRES
      type: POSTGRES

      # Configure the hostname of the external database
      hostname:

      # Configure the database name of the external database
      database:

      # Configure the username of the external database
      username:

      # Configure the password of the external database
      password:

  # Database Configuration for the Capella Collaboration Manager
  backend:
    # Define whether the database should also be deployed
    # in the cluster or whether it already exists externally.
    deploy: True

    # Username of an initial admin user
    # Is only set if the database is empty!
    initialAdmin: admin

    internal:
      ###### IF database.backend.deploy == True ######

      # Admin password of the database
      password: null

    external:
      ###### IF database.backend.deploy == False ######

      # Provide URI to the database in the format: postgresql://user:password@url:port/db_name
      uri: postgresql://user:password@url:port/db_name

valkey:
  password: null

backend:
  authentication:
    endpoints:
      wellKnown: http://dev-oauth-mock:8080/default/.well-known/openid-configuration
      # Override endpoint that authorizes the User
      # In the local development setup, use the following values:
      # - HTTP: http://localhost:8080/default/authorize
      # - HTTPS: https://localhost/default/authorize
      authorization: null

    claimMapping:
      idpIdentifier: sub
      username: preferred_username
      email: email

    scopes:
      - openid
      - profile
      - offline_access

    client:
      id: tbd
      secret: tbd

    # In the local development setup, use the following values:
    # - HTTP: http://localhost:8080/oauth2/callback
    # - HTTPS: https://localhost/oauth2/callback
    redirectURI: https://localhost/oauth2/callback

  # Namespace in which the Session Deployments / Pods should be spawned.
  # IMPORTANT: The namespace has to exist already
  k8sSessionNamespace: &sessionNamespace collab-sessions
  storageClassName: local-path
  storageAccessMode: ReadWriteOnce
  profiling: false

guacamole:
  username: guacadmin
  password: guacadmin

alerting:
  email:
    enabled: false
    host: smtp.example.com:587
    user: username
    password: password
    sender: capella@example.com

########################################
### KUBERNETES RELATED CONFIGURATION ###
########################################

# Activate the development mode.
# The deployment resources are reduced in the development mode.
development: false

# Specify if you'd like to use the oauth or smtp mocks
# Never set to True in production!
mocks:
  oauth: False
  smtp: False

cluster:
  kind: Kubernetes # Kubernetes | OpenShift

  ingressNamespace:

  podSecurityContext: &podSecurityContext
    runAsUser: 1004370000
    runAsGroup: 1004370000
    fsGroup: 1004370000
    runAsNonRoot: true

  containers:
    # The following values are appended to each container

  # Specify the name to the imagePullSecret in the namespace
  # It is used for the backend serviceAccount
  imagePullSecret: test

  # Specify the imagePullPolicy for all management portal containers
  imagePullPolicy: Always

  ingressClassName: nginx

  nodeSelector:

  namespaces:
    sessions:
      podSecurityContext: *podSecurityContext
      imagePullPolicy: Always
      # ingressClassName: nginx
      nodeSelector:

  pvc:
    storageClassName: local-path

  dns:
    service: kube-dns # dns-default for OpenShift
    namespace: kube-system # openshift-dns for OpenShift

  # Enable Vertical Pod Autoscaler for resource recommendations
  # If you want to enable it locally, install VPA first:
  # `make install-vpa`
  vpa:
    enabled: false

# Specify the NO_PROXY environment for the backend
# Leave it empty if not needed
proxy:
  no_proxy:

promtail:
  storageAccessMode: ReadWriteOnce
  storageClassName: local-path

# Default passwords for Grafana
grafana:
  adminUser: admin
  adminPassword: null

# https://github.com/grafana/loki/blob/main/production/helm/loki/values.yaml
loki:
  enabled: true
  global:
    image:
      registry: *externalRegistry
    dnsService: kube-dns # dns-default for OpenShift
    dnsNamespace: kube-system # openshift-dns for OpenShift
  loki:
    # Disabled X-Scope-OrgID authentication
    auth_enabled: False
    podSecurityContext: *podSecurityContext
    schemaConfig:
      configs:
        - from: 2023-01-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: index_
            period: 24h
  gateway:
    basicAuth:
      enabled: True
      username: localLokiUser
      password: null
    resources: &resourcesLoki
      limits:
        cpu: '1'
        memory: 500Mi
        ephemeral-storage: '2Gi'
      requests:
        cpu: '0.03'
        memory: 5Mi
        ephemeral-storage: '1Gi'
    affinity: null
    podSecurityContext: *podSecurityContext
  read:
    # Minimum 2 is required
    replicas: 2

    # We don't want to limit to specific nodes
    affinity: null
    resources: *resourcesLoki
  write:
    # Minimum 2 is required
    replicas: 2

    # We don't want to limit to specific nodes
    affinity: null
    resources: *resourcesLoki
  backend:
    # Minimum 2 is required
    replicas: 2

    # We don't want to limit to specific nodes
    affinity: null
    resources: *resourcesLoki
  sidecar:
    rules:
      enabled: False
  rbac:
    pspEnabled: False
    sccEnabled: False
    namespaced: True
  serviceAccount:
    # ServiceAccount doesn't work in OpenShift
    create: False
  monitoring:
    selfMonitoring:
      enabled: False
      grafanaAgent:
        installOperator: False
    lokiCanary:
      enabled: False
    alerts:
      enabled: False
    serviceMonitor:
      enabled: False
    rules:
      enabled: False
    dashboard:
      enabled: False
  test:
    enabled: False
  minio:
    enabled: True
    persistence:
      size: 10Gi
    configPathmc: /tmp/.mc
    securityContext:
      enabled: False
    resources: &resourcesMinio
      limits:
        cpu: '0.5'
        memory: 500Mi
        ephemeral-storage: '2Gi'
      requests:
        cpu: '0.03'
        memory: 5Mi
        ephemeral-storage: '1Gi'
    makePolicyJob: &minioJob
      resources: *resourcesMinio
      securityContext:
        enabled: True
        <<: *podSecurityContext
    makeUserJob: *minioJob
    makeServiceAccountJob: *minioJob
    makeBucketJob: *minioJob
    customCommandJob: *minioJob

# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-state-metrics/values.yaml
kube-state-metrics:
  enabled: true
  prometheusScrape: false
  rbac:
    useClusterRole: false
  securityContext: *podSecurityContext
  containerSecurityContext:
    runAsNonRoot: true
  collectors:
    - configmaps
    - cronjobs
    - deployments
    - ingresses
    - jobs
    - networkpolicies
    - persistentvolumeclaims
    - poddisruptionbudgets
    - pods
    - secrets
    - services
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
      ephemeral-storage: '2Gi'
    requests:
      cpu: 10m
      memory: 40Mi
      ephemeral-storage: '1Gi'
  namespaces: *sessionNamespace
  extraArgs:
    - '--metric-annotations-allowlist=pods=[*]'
    - '--metric-labels-allowlist=pods=[workload]'
